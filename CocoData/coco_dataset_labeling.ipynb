{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-08T20:53:35.934287Z",
     "start_time": "2025-03-08T20:53:35.930839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:53:37.173681Z",
     "start_time": "2025-03-08T20:53:37.170234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#train2017\n",
    "#val2017\n",
    "data_dir = 'train2017'\n",
    "panoptic_label_dir = 'panoptic_train2017'\n",
    "json_file = 'panoptic_train2017.json'\n",
    "files_to_check = [panoptic_label_dir, json_file]"
   ],
   "id": "ac7b5ada4a9d90bc",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:53:37.669540Z",
     "start_time": "2025-03-08T20:53:37.665541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_panoptic_label_dir_name = panoptic_label_dir + '_' + 'edited'\n",
    "save_panoptic_data_dir_name = data_dir + '_' + 'edited'\n",
    "save_dir = 'train_coco_dataset'\n",
    "save_panoptic_label_dir_path = (save_dir + '/' + save_panoptic_label_dir_name)\n",
    "save_panoptic_data_dir_path = (save_dir + '/' + save_panoptic_data_dir_name)"
   ],
   "id": "e759ed53e48b4dd5",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:53:39.084166Z",
     "start_time": "2025-03-08T20:53:39.080945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(save_panoptic_label_dir_path)\n",
    "print(save_panoptic_data_dir_path)"
   ],
   "id": "8b94dcbd3646491c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_coco_dataset/panoptic_train2017_edited\n",
      "train_coco_dataset/train2017_edited\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:54:03.884271Z",
     "start_time": "2025-03-08T20:54:03.879116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(save_panoptic_label_dir_path, exist_ok=True)\n",
    "os.makedirs(save_panoptic_data_dir_path, exist_ok=True)"
   ],
   "id": "5cd530ff7d626f98",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:54:04.276247Z",
     "start_time": "2025-03-08T20:54:04.271992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_file_endings(files_to_check, expected_ending):\n",
    "    for file_path in files_to_check:\n",
    "        if os.path.isfile(file_path):\n",
    "            result = re.search(r'_([^.]+)', os.path.basename(file_path)).group(1)\n",
    "            if result != expected_ending:\n",
    "                raise AssertionError(f\"Error: File '{file_path}' has ending '{result}', but expected '{expected_ending}'.\")\n",
    "        else:\n",
    "            if not file_path.endswith(expected_ending):\n",
    "                actual_ending = os.path.splitext(file_path)[-1]\n",
    "                raise AssertionError(f\"Error: File '{file_path}' does not end with '{expected_ending}', found ending '{actual_ending}' instead.\")\n"
   ],
   "id": "3318ca1a5d514410",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:54:04.723193Z",
     "start_time": "2025-03-08T20:54:04.719192Z"
    }
   },
   "cell_type": "code",
   "source": "check_file_endings(files_to_check, data_dir)",
   "id": "79b93503a9b7b70b",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:54:05.235162Z",
     "start_time": "2025-03-08T20:54:05.231699Z"
    }
   },
   "cell_type": "code",
   "source": "annotations_count = []",
   "id": "53c0f86bb13b4e3",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:54:09.892833Z",
     "start_time": "2025-03-08T20:54:05.699793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(json_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "for annotation in data['annotations']:\n",
    "    annotations_count.append(annotation['file_name'])"
   ],
   "id": "ae38a8dfb3e51b71",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:54:09.902540Z",
     "start_time": "2025-03-08T20:54:09.897192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_region(zeros_slice, bbox):\n",
    "    x, y, w, h = bbox\n",
    "    region = zeros_slice[y:y+h, x:x+w]\n",
    "    mask_zeros = zeros_slice == 255\n",
    "    mask_region = region == 255\n",
    "    return np.sum(mask_zeros) == np.sum(mask_region)\n",
    "\n",
    "\n",
    "def check_sizes(no_h_sizes, h_sizes, no_h_memory, h_memory, mask_layer_i):\n",
    "    # [obj1_size, obj2_size, ....]\n",
    "    filtered_no_h_iou = [ np.sum(mask_layer_i == 255)/ no_h_sizes[j] for j in range(len(no_h_memory)) if no_h_memory[j]]\n",
    "    # [hum1_size, hum2_size, .....]\n",
    "    filtered_h_iou = [ np.sum(mask_layer_i == 255)/ h_sizes[j] for j in range(len(h_memory)) if h_memory[j]]\n",
    "\n",
    "    max_no_h_iou = 0\n",
    "    max_h_iou = 0\n",
    "\n",
    "    for no_h_size in filtered_no_h_iou:\n",
    "        if no_h_size>max_no_h_iou:\n",
    "            max_no_h_iou = no_h_size\n",
    "    for h_size in filtered_h_iou:\n",
    "        if h_size>max_h_iou:\n",
    "            max_h_iou = h_size\n",
    "\n",
    "    if max_no_h_iou > max_h_iou:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "id": "16e70026486b2e73",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:54:11.361426Z",
     "start_time": "2025-03-08T20:54:09.910487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(annotations_count))\n",
    "print(len(os.listdir(data_dir)))\n",
    "print(len(os.listdir(panoptic_label_dir)))"
   ],
   "id": "a071b6f50381958",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118287\n",
      "118287\n",
      "52754\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T19:54:22.084228Z",
     "start_time": "2025-03-09T19:54:21.809483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_segments(annotations, filename):\n",
    "    human_bbox = []\n",
    "    no_human_bbox = []\n",
    "    obj_bbox = []\n",
    "    for annotation in annotations:\n",
    "        if annotation['file_name'] == filename:\n",
    "            for segment in annotation['segments_info']:\n",
    "                if segment['category_id'] == 1:\n",
    "                    human_bbox.append(segment)\n",
    "                elif 1 < segment['category_id'] <= 90:\n",
    "                    obj_bbox.append(segment)\n",
    "                elif segment['category_id'] >= 92:\n",
    "                    no_human_bbox.append(segment)\n",
    "    return human_bbox, no_human_bbox, obj_bbox\n",
    "\n",
    "def process_file(filename):\n",
    "    human_bbox, no_human_bbox, obj_bbox = extract_segments(data['annotations'], filename)\n",
    "    segments = {\n",
    "        1: human_bbox,  # Human segments\n",
    "        2: no_human_bbox,  # Non-human segments\n",
    "        3: obj_bbox,  # Object segments\n",
    "    }\n",
    "\n",
    "\n",
    "    im = cv2.imread(os.path.join(panoptic_label_dir, filename))\n",
    "    height, width, _ = im.shape\n",
    "    unique_colors = np.unique(im.reshape(-1, 3), axis=0)\n",
    "    mask_layers = np.zeros((len(unique_colors), height, width), dtype=np.uint8)\n",
    "\n",
    "    for i, color in enumerate(unique_colors):\n",
    "        mask = (im == color).all(axis=2)\n",
    "        mask_layers[i] = mask.astype(np.uint8) * 255\n",
    "\n",
    "        human_sizes = np.array([s['bbox'][2] * s['bbox'][3] for s in segments[1]])\n",
    "        non_human_sizes = np.array([s['bbox'][2] * s['bbox'][3] for s in segments[2]])\n",
    "        object_sizes = np.array([s['bbox'][2] * s['bbox'][3] for s in segments[3]])\n",
    "        human_masks = np.array([check_region(mask_layers[i], s['bbox']) for s in segments[1]])\n",
    "        non_human_masks = np.array([check_region(mask_layers[i], s['bbox']) for s in segments[2]])\n",
    "        object_masks = np.array([check_region(mask_layers[i], s['bbox']) for s in segments[3]])\n",
    "\n",
    "        if not np.any(human_masks):\n",
    "            mask_layers[i] = np.zeros_like(mask_layers[i])\n",
    "        elif np.any(human_masks) and np.any(non_human_masks) and check_sizes(non_human_sizes, human_sizes, non_human_masks, human_masks , mask_layers[i]):\n",
    "            mask_layers[i] = np.zeros_like(mask_layers[i])\n",
    "        elif np.any(human_masks) and np.any(object_masks) and check_sizes(object_sizes, human_sizes, object_masks, human_masks, mask_layers[i]):\n",
    "            mask_layers[i] = np.zeros_like(mask_layers[i])\n",
    "\n",
    "    overlay_sum = np.sum(mask_layers, axis=0)\n",
    "    if np.all(overlay_sum == 0):\n",
    "        return\n",
    "    base_name, ext = os.path.splitext(filename)\n",
    "    cv2.imwrite(f\"{save_panoptic_label_dir_path}/{filename}\", overlay_sum)\n",
    "    shutil.copy(f'{data_dir}/{base_name}.jpg', f\"{save_panoptic_data_dir_path}/{base_name}.jpg\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    filenames = os.listdir(panoptic_label_dir)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "        list(tqdm(executor.map(process_file, filenames), desc=\"Processing files\", unit=\"file\", total=len(filenames)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "ef0a4e2cd0aa7d7d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 71\u001B[0m\n\u001B[0;32m     68\u001B[0m         \u001B[38;5;28mlist\u001B[39m(tqdm(executor\u001B[38;5;241m.\u001B[39mmap(process_file, filenames), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcessing files\u001B[39m\u001B[38;5;124m\"\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile\u001B[39m\u001B[38;5;124m\"\u001B[39m, total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(filenames)))\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 71\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[1], line 65\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmain\u001B[39m():\n\u001B[1;32m---> 65\u001B[0m     filenames \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241m.\u001B[39mlistdir(panoptic_label_dir)\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ThreadPoolExecutor(max_workers\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mcpu_count()) \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[0;32m     68\u001B[0m         \u001B[38;5;28mlist\u001B[39m(tqdm(executor\u001B[38;5;241m.\u001B[39mmap(process_file, filenames), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcessing files\u001B[39m\u001B[38;5;124m\"\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile\u001B[39m\u001B[38;5;124m\"\u001B[39m, total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(filenames)))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'os' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9797d88bd28a137c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
